{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor Market finance - expected return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons créer un modèle de prévision d'expected return d'un portefeuille.\n",
    "<br/> Le but sera d'essayer de minimiser l'écart entre nos prédictions et les valeurs observé\n",
    "<br/> <b>Intérêt :</b> Anticipé les pertes afin de mieux gérer notre portefeuille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Description du fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier train.csv contient les colonnes suivantes : \n",
    "<br/>Id => Id de l'asset \n",
    "<br/>Feature_i avec i de 1:25 => Des features descriptives de l'actif sans information complémentaire sur leur manière d'être calculé\n",
    "<br/>Ret_MinusTwo,Ret_MinusOne => Les returns (rentabilité) connues à D-2 (Day - 2) et D-1 (Day - 1)\n",
    "<br/>Ret_i avec i de 1:119 => Les returns connues pdt les deux dernières heures de la journée courante\n",
    "<br/>Ret_i avec i de 12O:180 => Les returns qu'on <b>veut essayer de prédire </b>\n",
    "<br/>Ret_PlusOne, Ret_PlusTwo => Les return à D+1 et D+2 qu'on <b>veut essayer de prédire</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Créer des fonctions permettant de:\n",
    "<br/>a-Créer un jeu de train et test de manière aléatoire\n",
    "<br/>b-Lancer le modèle xgboost avec un jeu de paramètre donné\n",
    "<br/><b>Cette question va être corrigé</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)Créer et sélectionner les variables à partir des données existantes pour essayer de prédire plus efficacement:\n",
    "<br/>a-Ret_120\n",
    "<br/>b-Ret_PlusOne\n",
    "<br/>Une ébauche de réponse va être incluse => <b><u>A compléter par vos soins et me renvoyer le notebook</u> si vous choisissez ce problème</b>\n",
    "<br/>Pas de problème si le résultat n'est pas sensiblement améliorer, je veux que vous m'expliquiez l'idée que vous aviez surtout!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de l'environnement de développement et réponse à la première question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pfisz010614\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Inclusion de toutes les librairies qui seront nécessaire \n",
    "# xgboost => librairie optimisé utilisant le model de descente du gradient optimisé: http://xgboost.readthedocs.io/en/latest/model.html \n",
    "import xgboost as xgb\n",
    "# train_test_split => Fonctionnalité très utile pour créer ses datasets de test et de train\n",
    "from sklearn.model_selection import train_test_split\n",
    "# pandas => Librairie pour manipulé toute sorte de tableau\n",
    "import pandas as pd\n",
    "# numpy => librairie pour les agrégats et tableau avec des valeurs numériques \n",
    "# (modélisation différente entre les arrays numpy et les dataframes pandas)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Le path vers le fichier que vous avez en local\n",
    "filepath = 'D:/Formation/Dauphine/TP2/Market_Finance/train.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctionnalité pour les csv: pd.read_csv pr excel c'est pd.read_excel \n",
    "# Il y a de multiples paramètrages possible \n",
    "df_train = pd.read_csv(filepath, sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction utile pour pouvoir rapidement faire la selection de columns qu'on veut garder pr réduire le dataframe\n",
    "def print_columns_dataframe(df):\n",
    "    for value in df.columns:     \n",
    "        print(\"'\" + value + \"',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcul de erreur au carre\n",
    "def erreur_carre(preds, y, weight):\n",
    "    ylist = y.tolist()\n",
    "    erreur = []\n",
    "    sumresult_ = 0\n",
    "    for i in range(0, len(preds)):\n",
    "        er_tmp = weight[i] * (preds[i] - ylist[i])**2\n",
    "        erreur.append(er_tmp)\n",
    "        sumresult_ = sumresult_ + er_tmp\n",
    "    return erreur, sumresult_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calcul de l'erreur absolue\n",
    "def erreur_absolu(preds, y, weight):\n",
    "    ylist = y.tolist()\n",
    "    erreur = []\n",
    "    sumresult_ = 0\n",
    "    for i in range(0, len(preds)):\n",
    "        er_tmp = weight[i] *  abs(preds[i] - ylist[i])\n",
    "        erreur.append(er_tmp)\n",
    "        sumresult_ = sumresult_ + er_tmp\n",
    "    return erreur, sumresult_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcul_model(dataset, test_size, y, param, num_round, rnd):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=test_size, random_state=rnd)\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    # make prediction\n",
    "    preds = bst.predict(dtest)\n",
    "    return y_test, preds, bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcul_model_erreur(prediction, y_output, weight, error_type):\n",
    "    if error_type == 'absolue':\n",
    "        erreur, result = erreur_absolu(prediction, y_output, equal_weight)\n",
    "    elif error_type == 'carre':\n",
    "        erreur, result = erreur_carre(prediction, y_output, equal_weight)\n",
    "    else:\n",
    "        print('erreur pour le paramètre error_type: ' + error_type) \n",
    "        return None\n",
    "    df_erreur = pd.DataFrame(np.transpose(erreur), columns=['erreur'])\n",
    "    df_output = pd.concat([pd.DataFrame(np.transpose(y_output.tolist()), columns=['y_output']), pd.DataFrame(np.transpose(pred), columns=['preds']),df_erreur], axis=1)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Id',\n",
      "'Feature_1',\n",
      "'Feature_2',\n",
      "'Feature_3',\n",
      "'Feature_4',\n",
      "'Feature_5',\n",
      "'Feature_6',\n",
      "'Feature_7',\n",
      "'Feature_8',\n",
      "'Feature_9',\n",
      "'Feature_10',\n",
      "'Feature_11',\n",
      "'Feature_12',\n",
      "'Feature_13',\n",
      "'Feature_14',\n",
      "'Feature_15',\n",
      "'Feature_16',\n",
      "'Feature_17',\n",
      "'Feature_18',\n",
      "'Feature_19',\n",
      "'Feature_20',\n",
      "'Feature_21',\n",
      "'Feature_22',\n",
      "'Feature_23',\n",
      "'Feature_24',\n",
      "'Feature_25',\n",
      "'Ret_MinusTwo',\n",
      "'Ret_MinusOne',\n",
      "'Ret_2',\n",
      "'Ret_3',\n",
      "'Ret_4',\n",
      "'Ret_5',\n",
      "'Ret_6',\n",
      "'Ret_7',\n",
      "'Ret_8',\n",
      "'Ret_9',\n",
      "'Ret_10',\n",
      "'Ret_11',\n",
      "'Ret_12',\n",
      "'Ret_13',\n",
      "'Ret_14',\n",
      "'Ret_15',\n",
      "'Ret_16',\n",
      "'Ret_17',\n",
      "'Ret_18',\n",
      "'Ret_19',\n",
      "'Ret_20',\n",
      "'Ret_21',\n",
      "'Ret_22',\n",
      "'Ret_23',\n",
      "'Ret_24',\n",
      "'Ret_25',\n",
      "'Ret_26',\n",
      "'Ret_27',\n",
      "'Ret_28',\n",
      "'Ret_29',\n",
      "'Ret_30',\n",
      "'Ret_31',\n",
      "'Ret_32',\n",
      "'Ret_33',\n",
      "'Ret_34',\n",
      "'Ret_35',\n",
      "'Ret_36',\n",
      "'Ret_37',\n",
      "'Ret_38',\n",
      "'Ret_39',\n",
      "'Ret_40',\n",
      "'Ret_41',\n",
      "'Ret_42',\n",
      "'Ret_43',\n",
      "'Ret_44',\n",
      "'Ret_45',\n",
      "'Ret_46',\n",
      "'Ret_47',\n",
      "'Ret_48',\n",
      "'Ret_49',\n",
      "'Ret_50',\n",
      "'Ret_51',\n",
      "'Ret_52',\n",
      "'Ret_53',\n",
      "'Ret_54',\n",
      "'Ret_55',\n",
      "'Ret_56',\n",
      "'Ret_57',\n",
      "'Ret_58',\n",
      "'Ret_59',\n",
      "'Ret_60',\n",
      "'Ret_61',\n",
      "'Ret_62',\n",
      "'Ret_63',\n",
      "'Ret_64',\n",
      "'Ret_65',\n",
      "'Ret_66',\n",
      "'Ret_67',\n",
      "'Ret_68',\n",
      "'Ret_69',\n",
      "'Ret_70',\n",
      "'Ret_71',\n",
      "'Ret_72',\n",
      "'Ret_73',\n",
      "'Ret_74',\n",
      "'Ret_75',\n",
      "'Ret_76',\n",
      "'Ret_77',\n",
      "'Ret_78',\n",
      "'Ret_79',\n",
      "'Ret_80',\n",
      "'Ret_81',\n",
      "'Ret_82',\n",
      "'Ret_83',\n",
      "'Ret_84',\n",
      "'Ret_85',\n",
      "'Ret_86',\n",
      "'Ret_87',\n",
      "'Ret_88',\n",
      "'Ret_89',\n",
      "'Ret_90',\n",
      "'Ret_91',\n",
      "'Ret_92',\n",
      "'Ret_93',\n",
      "'Ret_94',\n",
      "'Ret_95',\n",
      "'Ret_96',\n",
      "'Ret_97',\n",
      "'Ret_98',\n",
      "'Ret_99',\n",
      "'Ret_100',\n",
      "'Ret_101',\n",
      "'Ret_102',\n",
      "'Ret_103',\n",
      "'Ret_104',\n",
      "'Ret_105',\n",
      "'Ret_106',\n",
      "'Ret_107',\n",
      "'Ret_108',\n",
      "'Ret_109',\n",
      "'Ret_110',\n",
      "'Ret_111',\n",
      "'Ret_112',\n",
      "'Ret_113',\n",
      "'Ret_114',\n",
      "'Ret_115',\n",
      "'Ret_116',\n",
      "'Ret_117',\n",
      "'Ret_118',\n",
      "'Ret_119',\n",
      "'Ret_120',\n",
      "'Ret_121',\n",
      "'Ret_122',\n",
      "'Ret_123',\n",
      "'Ret_124',\n",
      "'Ret_125',\n",
      "'Ret_126',\n",
      "'Ret_127',\n",
      "'Ret_128',\n",
      "'Ret_129',\n",
      "'Ret_130',\n",
      "'Ret_131',\n",
      "'Ret_132',\n",
      "'Ret_133',\n",
      "'Ret_134',\n",
      "'Ret_135',\n",
      "'Ret_136',\n",
      "'Ret_137',\n",
      "'Ret_138',\n",
      "'Ret_139',\n",
      "'Ret_140',\n",
      "'Ret_141',\n",
      "'Ret_142',\n",
      "'Ret_143',\n",
      "'Ret_144',\n",
      "'Ret_145',\n",
      "'Ret_146',\n",
      "'Ret_147',\n",
      "'Ret_148',\n",
      "'Ret_149',\n",
      "'Ret_150',\n",
      "'Ret_151',\n",
      "'Ret_152',\n",
      "'Ret_153',\n",
      "'Ret_154',\n",
      "'Ret_155',\n",
      "'Ret_156',\n",
      "'Ret_157',\n",
      "'Ret_158',\n",
      "'Ret_159',\n",
      "'Ret_160',\n",
      "'Ret_161',\n",
      "'Ret_162',\n",
      "'Ret_163',\n",
      "'Ret_164',\n",
      "'Ret_165',\n",
      "'Ret_166',\n",
      "'Ret_167',\n",
      "'Ret_168',\n",
      "'Ret_169',\n",
      "'Ret_170',\n",
      "'Ret_171',\n",
      "'Ret_172',\n",
      "'Ret_173',\n",
      "'Ret_174',\n",
      "'Ret_175',\n",
      "'Ret_176',\n",
      "'Ret_177',\n",
      "'Ret_178',\n",
      "'Ret_179',\n",
      "'Ret_180',\n",
      "'Ret_PlusOne',\n",
      "'Ret_PlusTwo',\n",
      "'Weight_Intraday',\n",
      "'Weight_Daily',\n"
     ]
    }
   ],
   "source": [
    "print_columns_dataframe(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Exclusion de l'Id et de toutes les colonnes à prédire\n",
    "dataset = df_train.drop(columns=['Ret_120','Ret_121','Ret_122','Ret_123','Ret_124','Ret_125','Ret_126','Ret_127','Ret_128','Ret_129',\n",
    "'Ret_130','Ret_131','Ret_132','Ret_133','Ret_134','Ret_135','Ret_136','Ret_137','Ret_138','Ret_139','Ret_140','Ret_141','Ret_142','Ret_143','Ret_144','Ret_145','Ret_146','Ret_147','Ret_148','Ret_149','Ret_150','Ret_151','Ret_152','Ret_153','Ret_154','Ret_155','Ret_156','Ret_157','Ret_158','Ret_159','Ret_160','Ret_161','Ret_162','Ret_163','Ret_164','Ret_165','Ret_166','Ret_167','Ret_168',\n",
    "'Ret_169','Ret_170','Ret_171','Ret_172','Ret_173','Ret_174','Ret_175','Ret_176','Ret_177','Ret_178','Ret_179','Ret_180','Ret_PlusOne', 'Ret_PlusTwo','Weight_Intraday','Weight_Daily']) #'Id',\n",
    "dataset_no_id = dataset.drop(columns='Id') \n",
    "dataset_no_id = dataset_no_id.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Toutes les rentabilités que l'on pourrait vouloir essayer de résoudre\n",
    "y_ret_120 = df_train['Ret_120']\n",
    "y_ret_180 = df_train['Ret_180']\n",
    "y_ret_d_1 = df_train['Ret_PlusOne']\n",
    "y_ret_d_2 =df_train['Ret_PlusTwo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Les poids qui seront nécessaire pour le calcul de la fonction d'erreur\n",
    "weight_intra = df_train['Weight_Intraday'].tolist() # à utiliser pour prédire Ret_120 & Ret_180\n",
    "weight_daily = df_train['Weight_Daily'].tolist()    # à utiliser pour prédire Ret_PlusOne & Ret_PlusTwo\n",
    "equal_weight = [1] * len(weight_daily) # pour faire nos test avant de chercher à optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un jeu de paramètre à pour le modèle xgboos\n",
    "# max_depth : Profondeur max des arbres\n",
    "# eta : coefficient de la courbe d'apprentissage (learning_curve)\n",
    "# silent : verbose\n",
    "# tous les paramètres sont détaillés ici http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "param = {'max_depth':6, 'eta':0.225, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output, pred, bst = calcul_model(dataset_no_id, 0.33, y_ret_120, param, 400, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.922132918179315"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcul de l'erreur avec la fonction d'erreur absolue\n",
    "df_output_absolue = calcul_model_erreur(pred, y_output, equal_weight, 'absolue')\n",
    "df_output_absolue.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023223128276449508"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul de l'erreur avec la fonction d'erreur au carree\n",
    "param_carre = {'max_depth':6, 'eta':0.225, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'rmse','lambda':1.5} #,'gamma':1.5\n",
    "df_output_carre = calcul_model_erreur(pred, y_output, equal_weight, 'carre')\n",
    "df_output_carre.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur pour le paramètre error_type: blabla\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_test = calcul_model_erreur(pred, y_output, equal_weight, 'blabla')\n",
    "type(df_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.414808717998726"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_180 = {'max_depth':6, 'eta':0.225, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output_180, pred_180, bst_180 = calcul_model(dataset_no_id, 0.33, y_ret_180, param_180, 400, 42)\n",
    "df_output_absolue_180 = calcul_model_erreur(pred_180, y_output_180, equal_weight, 'absolue')\n",
    "df_output_absolue_180.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.76110391805906"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_d_1 = {'max_depth':6, 'eta':0.225, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'rmaemse','lambda':1.5} #,'gamma':1.5\n",
    "y_output_d_1, pred_d_1, bst_d_1 = calcul_model(dataset_no_id, 0.33, y_ret_d_1, param_d_1, 400, 42)\n",
    "df_output_absolue = calcul_model_erreur(pred_d_1, y_output_d_1, equal_weight, 'absolue')\n",
    "df_output_absolue.erreur.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé comme valeur de référence la prédiction que nous avons obtenu pour la question 1 pour y_180 et y_d_1.\n",
    "<br/>Il y a deux axes pour améliorer la prédiction : \n",
    "<br/><ul>1.optimiser les paramètres de xgboost\n",
    "<br/>2.Transformer les variables afin d'obtenir plus d'information</ul>\n",
    "Une idée de variable va vous être proposé et vous aurez à compléter la question/créer de nouvelles variables/modifier les paramètres de xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous est des exemples de bout de code pour créer des nouvelles variables ou des sous selection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comptage du nombre de return positive / négative\n",
    "unpivot_Ret = pd.melt(df_train,value_name='Return_time',value_vars= ['Ret_2', 'Ret_3', 'Ret_4', 'Ret_5', 'Ret_6', 'Ret_7', 'Ret_8', 'Ret_9', 'Ret_10', 'Ret_11', 'Ret_12', 'Ret_13', 'Ret_14', 'Ret_15', 'Ret_16', 'Ret_17', 'Ret_18', 'Ret_19', 'Ret_20', 'Ret_21', 'Ret_22', 'Ret_23', 'Ret_24', 'Ret_25', 'Ret_26', 'Ret_27', 'Ret_28', 'Ret_29', 'Ret_30', 'Ret_31', 'Ret_32', 'Ret_33', 'Ret_34', 'Ret_35', 'Ret_36', 'Ret_37', 'Ret_38', 'Ret_39', 'Ret_40', 'Ret_41', 'Ret_42', 'Ret_43', 'Ret_44', 'Ret_45', 'Ret_46', 'Ret_47', 'Ret_48', 'Ret_49', 'Ret_50', 'Ret_51', 'Ret_52', 'Ret_53', 'Ret_54', 'Ret_55', 'Ret_56', 'Ret_57', 'Ret_58', 'Ret_59', 'Ret_60', 'Ret_61', 'Ret_62', 'Ret_63', 'Ret_64', 'Ret_65', 'Ret_66', 'Ret_67', 'Ret_68', 'Ret_69', 'Ret_70', 'Ret_71', 'Ret_72', 'Ret_73', 'Ret_74', 'Ret_75', 'Ret_76', 'Ret_77', 'Ret_78', 'Ret_79', 'Ret_80', 'Ret_81', 'Ret_82', 'Ret_83', 'Ret_84', 'Ret_85', 'Ret_86', 'Ret_87', 'Ret_88', 'Ret_89', 'Ret_90', 'Ret_91', 'Ret_92', 'Ret_93', 'Ret_94', 'Ret_95', 'Ret_96', 'Ret_97', 'Ret_98', 'Ret_99', 'Ret_100', 'Ret_101', 'Ret_102', 'Ret_103', 'Ret_104', 'Ret_105', 'Ret_106', 'Ret_107', 'Ret_108', 'Ret_109', 'Ret_110', 'Ret_111', 'Ret_112', 'Ret_113', 'Ret_114', 'Ret_115', 'Ret_116', 'Ret_117', 'Ret_118', 'Ret_119'], id_vars='Id')\n",
    "unpivot_Ret['Sens_return'] = np.where(unpivot_Ret.Return_time < 0, 'Number of Negative' , 'Number of positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calcul d'indicateur simple sur les return de 2 à 119\n",
    "ret_number = pd.pivot_table(unpivot_Ret, values ='Return_time', columns='Sens_return', index='Id', aggfunc=len)\n",
    "ret_number = ret_number.reset_index()\n",
    "ret_stat = pd.pivot_table(unpivot_Ret, values ='Return_time', index='Id', aggfunc=[np.mean, np.min, np.max, np.std, np.median])\n",
    "ret_stat.columns = [\"|\".join((j,k)) for j,k in ret_stat.columns]\n",
    "ret_stat = ret_stat.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge des nouvelles variables calculées\n",
    "dataset = dataset.merge(ret_stat, on='Id', how='inner')\n",
    "dataset = dataset.merge(ret_number, on='Id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_day_one = df_train['Ret_PlusOne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection d'un sous dataset\n",
    "dataset_2 = dataset[['Feature_1','Feature_2', 'Feature_3','Feature_4', 'Feature_5','Feature_6',\n",
    "                   'Feature_7','Feature_8', 'Feature_9','Feature_10','Feature_11','Feature_12',\n",
    "                   'Feature_13','Feature_14','Feature_15','Feature_16','Feature_17','Feature_18',\n",
    "                   'Feature_19','Feature_20', 'Feature_21','Feature_22','Feature_23','Feature_24',\n",
    "                   'Feature_25','Ret_MinusTwo','Ret_MinusOne','Ret_2','Ret_60', 'Ret_109', 'Ret_110', 'Ret_111', \n",
    "                    'Ret_112', 'Ret_113', 'Ret_114', 'Ret_115', 'Ret_116', 'Ret_117', 'Ret_118','Ret_119',\n",
    "                   'mean|Return_time', 'Number of Negative','Number of positive', 'std|Return_time','median|Return_time']]\n",
    "# 'amin|Return_time', 'amax|Return_time',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division par exemple du problème en deux partie (débile car je dis diviser selon day-1... mais il y a surement mieux à faire :) )\n",
    "dataset_2_neg = dataset_2[dataset_2.Ret_MinusOne<0]\n",
    "y_neg = df_train[df_train.Ret_MinusOne<0]['Ret_PlusOne']\n",
    "dataset_2_pos = dataset_2[dataset_2.Ret_MinusOne>0]\n",
    "y_pos = df_train[df_train.Ret_MinusOne>0]['Ret_PlusOne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.9744011113247"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle avec la valeur de référence qu'on va essayer de battre\n",
    "param_d_1 = {'max_depth':5, 'eta':0.1, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output_d_1, pred_d_1, bst_d_1 = calcul_model(dataset_no_id, 0.33, y_day_one, param_d_1, 150, 42)\n",
    "df_output_absolue_d_1 = calcul_model_erreur(pred_d_1, y_output_d_1, equal_weight, 'absolue')\n",
    "df_output_absolue_d_1.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.38490953963412"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcul du modèle avec le sous dataset\n",
    "param_d_1 = {'max_depth':5, 'eta':0.1, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output_d_1, pred_d_1, bst_d_1 = calcul_model(dataset_2, 0.33, y_day_one, param_d_1, 150, 42)\n",
    "df_output_absolue_d_1 = calcul_model_erreur(pred_d_1, y_output_d_1, equal_weight, 'absolue')\n",
    "df_output_absolue_d_1.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.44475495877205"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcul du modèle divisé en 2 (1/2)\n",
    "param_d_1 = {'max_depth':5, 'eta':0.1, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output_d_1_neg, pred_d_1_neg, bst_d_1_neg = calcul_model(dataset_2_neg, 0.33, y_neg, param_d_1, 150, 42)\n",
    "df_output_absolue_d_1_neg = calcul_model_erreur(pred_d_1_neg, y_output_d_1_neg, equal_weight, 'absolue')\n",
    "df_output_absolue_d_1_neg.erreur.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.49453736952788"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcul du modèle divisé en 2 (2/2)\n",
    "param_d_1 = {'max_depth':5, 'eta':0.1, 'silent': 0, 'objective':'reg:linear', 'eval_metric': 'mae','lambda':1.5} #,'gamma':1.5\n",
    "y_output_d_1_pos, pred_d_1_pos, bst_d_1_pos = calcul_model(dataset_2_pos, 0.33, y_pos, param_d_1, 150, 42)\n",
    "df_output_absolue_d_1_pos = calcul_model_erreur(pred_d_1_pos, y_output_d_1_pos, equal_weight, 'absolue')\n",
    "df_output_absolue_d_1_pos.erreur.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant c'est à vous de jouer : Reprendre toutes les parties du code que vous voulez pour essayer de prédire mieux que le modèle de référence (vous pouvez utiliser les poids que vous préférez)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
